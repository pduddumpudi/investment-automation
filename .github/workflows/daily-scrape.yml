name: Daily Investment Data Update

on:
  schedule:
    # Normal days: 10 AM UTC
    - cron: '0 10 * * *'
    # 13F filing periods (Feb, May, Aug, Nov 1-20): Also run at 6 PM UTC
    - cron: '0 18 1-20 2,5,8,11 *'
  workflow_dispatch:  # Allow manual trigger
    inputs:
      force_scrape:
        description: 'Force full scrape (ignore incremental)'
        type: boolean
        default: false

permissions:
  contents: write
  pages: write
  issues: write

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: docs-src/package-lock.json

      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt

      - name: Install Node dependencies
        run: |
          cd docs-src
          npm ci

      - name: Run scraper
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          if [ "${{ github.event.inputs.force_scrape }}" == "true" ]; then
            python src/main.py --force
          else
            python src/main.py
          fi
        continue-on-error: true

      - name: Copy data to docs folder
        run: |
          mkdir -p docs/data
          cp data/stocks.json docs/data/
          cp data/stocks.csv docs/data/ 2>/dev/null || true

      - name: Build React frontend
        run: |
          cd docs-src
          npm run build

      - name: Check if data was updated
        id: check_changes
        run: |
          if git diff --quiet data/ docs/; then
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          git add data/ docs/
          git commit -m "Update investment data - $(date -u +'%Y-%m-%d %H:%M UTC')

          ü§ñ Generated with [Claude Code](https://claude.com/claude-code)"
          git push

      - name: Deploy to GitHub Pages
        if: steps.check_changes.outputs.changed == 'true'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs
          cname: # Optional: Add custom domain here

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '‚ö†Ô∏è Daily scraping workflow failed',
              body: `The automated scraping workflow failed on ${new Date().toISOString()}.

              **Run:** ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}

              Please check the logs for details.`,
              labels: ['automated', 'bug']
            })
