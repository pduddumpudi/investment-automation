name: Daily Investment Data Update

on:
  schedule:
    # Run daily at 10 AM UTC (adjust as needed)
    - cron: '0 10 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          playwright install chromium
          playwright install-deps chromium

      - name: Run scraper
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python src/main.py
        continue-on-error: true

      - name: Check if data was updated
        id: check_changes
        run: |
          if git diff --quiet data/; then
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          git add data/
          git commit -m "Update investment data - $(date -u +'%Y-%m-%d %H:%M UTC')"
          git push

      - name: Deploy to GitHub Pages
        if: steps.check_changes.outputs.changed == 'true'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs
          cname: # Optional: Add custom domain here

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '⚠️ Daily scraping workflow failed',
              body: `The automated scraping workflow failed on ${new Date().toISOString()}.

              **Run:** ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}

              Please check the logs for details.`,
              labels: ['automated', 'bug']
            })
